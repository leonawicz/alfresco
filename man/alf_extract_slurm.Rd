% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/slurm.R
\name{alf_extract_slurm}
\alias{alf_extract_slurm}
\title{Slurm script for ALFRESCO data extractions}
\usage{
alf_extract_slurm(out_dir = alfdef()$alf_slurm_dir,
  file = "alf_extract.R", ntasks, nodes, ntasks_per_node,
  exclusive = TRUE, domain = "akcan1km", rmpi = TRUE,
  modelIndex = NULL, project = NULL, years = NULL, reps = NULL,
  cru = NULL, repSample = NULL, locgroup = NULL,
  email = "mfleonawicz@alaska.edu", partition = "main",
  copy_rscript = TRUE, max_cores = 32)
}
\arguments{
\item{out_dir}{the directory containing \code{file}. This is where the slurm script is to be saved and executed from.}

\item{file}{the R script to be called by \code{Rscript} when the generated slurm script is executed.
May be similarly generated by this function. See \code{copy_rscript} below.}

\item{ntasks}{numeric, SLURM number of tasks. See details.}

\item{nodes}{numeric, SLURM number of compute nodes. See details.}

\item{ntasks_per_node}{numeric, SLURM number of tasks per node. See details.}

\item{exclusive}{logical, put nodes into exclusive use for the job when the generated slurm script is executed. Defaults to \code{TRUE}.}

\item{domain}{character, the ALFRESCO run spatial domain, either \code{"akcan1km"} or \code{"ak1km"}.}

\item{rmpi}{logical, use \code{Rmpi}, defaults to \code{TRUE}.}

\item{modelIndex}{integer, iterator, refers to the position in the list of a project's ALFRESCO model run GCM/RCP output directories.}

\item{project}{character, a (new) project name for extracted data. It need not match any directory names pertaining to the raw ALFRESCO outputs.}

\item{years}{numeric vector of years for data extraction.}

\item{reps}{numeric vector of ALFRESCO simulation replicates for data extraction, e.g. \code{1:200}.}

\item{cru}{logical, whether data extraction is for historical years (ALFRESCO runs based on CRU data) or projected years (GCM data).}

\item{repSample}{optional numeric vector of reps for subsampling, e.g., \code{1:30}.}

\item{locgroup}{optional character string naming a specific Location Group to process extraction for instead of all Location Groups.}

\item{email}{defaults to the author/maintainer/user.}

\item{partition}{defaults to \code{"main"}.}

\item{copy_rscript}{logical, also copy template R script from \code{alfresco} package along with the generated slurm script. Defaults to \code{TRUE}.}

\item{max_cores}{maximum number of processors to use on a single Atlas node, defaults to 32.}
}
\description{
Generate slurm script for ALFRESCO data extractions from output maps.
}
\details{
This function is used for generating a slurm script that is used for extracting data from ALFRESCO geotiff map outputs for subsequent analyses.
The generated slurm script leverages \code{Rmpi} for multi-node cluster processing.
It is used to call an R script with \code{Rscript}, e.g., that created by \link{alf_extract_rscript}.
The scripts are typically used in this fashion, but they can also be generating with \code{rmpi = FALSE}, in which case \code{nodes}
need only be 1.

Formal SLURM job arguments are passed by \code{ntasks}, \code{nodes}, \code{ntasks_per_node}, \code{exclusive}, \code{email} and \code{partition}.
General script setup arguments include \code{out_dir}, \code{file}, \code{copy_rscript} and \code{max_cores}.
All other arguments refer to those passed to the \code{Rscript} call within the slurm script.
Any of these that are \code{NULL} are ignored and it is assumed they will be passed explicitly as name-value pairs (in any order)
at the command line by the user when the generated slurm script is executed.
Any of these arguments that are not \code{NULL} are hardcoded into the string of arguments listed after \code{Rscript}.

This provides flexible generality when generating ALFRESCO data extraction slurm scripts.
Note that the number of non-null arguments among these decreases the number of available general arguments available at the command line
when the script is executed. For example, if seven of the nine arguments available to \code{Rscript} are hardcoded into the slurm
script by passing them to \code{alf_extract_slurm} explicitly, then the generated script will show only an additional \code{$1 $2}
after the fixed arguments rather than \code{$1 $2... $9}.

If \code{years} is missing, then the formal SLURM job arguments \code{ntasks}, \code{nodes} and \code{ntasks_per_node}
must be provided and it is assumed that a year range that matches the number of tasks will be provided when the slurm script is executed.
These arguments are always intended to be hardcoded into a generated script.

Alternatively, if \code{years} is provided explicitly, then if these job arguments are missing they can be inferred internally
based on the number of years to be processed using the script and the \code{max_cores} to be used per node.
Since these scripts are run on SNAP's Atlas cluster, the default \code{max_cores} is 32.
This can be lowered for intensive extraction jobs that
may reach node RAM limits otherwise.

Note that this function is intended to be run on the Atlas cluster. If you make a bash script like this on Windows,
you may have to run a command line utility like \code{dos2unix} on the file.
}
\examples{
\dontrun{
alf_extract_slurm(
  domain = "ak1km", project = "JFSP", years = 1950:2013,
  reps = 1:32, cru = TRUE
)
}
}
